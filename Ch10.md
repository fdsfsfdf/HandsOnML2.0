Ch10. 케라스를 사용한 인공 신경망 소개

	- 인공지능을 어떻게 구현 할 수 있을까? -> 인공 신경망(ANN)을 떠올리게 됨.
	  => 하지만 생물학적 뉴런에서 영감을 얻었다고 무조건 따라가기 보다는 장점을 취하고 단점은 보완할 수 있게 구조를 변경하는 방향으로 나아가는 중.
	- 생각보다 로컬미니멈의 문제는 실전에서는 문제가 되지 않음. 이런 경우가 매우 드물 뿐더러 설사 로컬미니멈에 도달하더라도 글로벌 미니멈에 매우 가까움.
10.1

	- 1번 : 항등 함수 = A가 1이면 C도 1 
	- 2번 : 논리 곱 연산 = A와 B가 모두 1이면 C가 1
	- 3번 : 논리 합 연산 = A나 B 중 하나라도 1이면 C가 1 
	- 4번 : 논리 곱 + 부정 = A가 1이고 B는 꺼져있야 C가 1 

- 퍼셉트론
	- TLU(Threshold logic unit)으로 불리는 인공 뉴런 기반 인공 신경망
	- 입력과 출력이 이진수가 아닌 어떤 숫자이고, 각각의 입력은 가중치와 연관됨.
	- TLU는 입력의 가중치 합(w*x의 시그마)을 계산한뒤 이 합에 step ftn을 적용하여 결과 출력. 
	- 퍼셉트론은 층이 하나 뿐인 TLU로 구성됨. 
	- 한 층의 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있는 층을 Fully Connected Layer or Dense layer 라고 함. 
	- 퍼셉트론의 입력은 input layer를 통하는데, 이 층은 그냥 출력으로 통과시킨다. 거기에 Bias가 더해짐. 
	- 위의 퍼셉트론은 세 개의 다른 이진 클래스로 동시에 분류할 수 있으므로 다중 출력 분류기임. 
